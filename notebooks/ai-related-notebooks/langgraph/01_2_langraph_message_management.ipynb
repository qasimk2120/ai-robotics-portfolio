{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c1f944d",
   "metadata": {},
   "source": [
    "# LangGraph Message Accumulation with Reducers\n",
    "\n",
    "This notebook demonstrates how **LangGraph reducers** enable\n",
    "persistent conversational state by **accumulating messages**\n",
    "instead of overwriting them.\n",
    "\n",
    "The focus is on:\n",
    "- Using `add_messages` as a reducer\n",
    "- Understanding `Annotated` state fields\n",
    "- Building a multi-turn conversational graph\n",
    "- Conditional routing with preserved context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa9e3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langgraph.graph import START, END, StateGraph, add_messages\n",
    "from langchain_core.messages import HumanMessage, BaseMessage, AIMessage\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "from collections.abc import Sequence\n",
    "from typing import Literal, Annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ab934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd74966",
   "metadata": {},
   "source": [
    "## Message Reducer: `add_messages`\n",
    "\n",
    "`add_messages` is a **reducer function** that defines how\n",
    "two lists of messages are merged.\n",
    "\n",
    "It takes:\n",
    "1. The existing list of messages\n",
    "2. The newly returned messages\n",
    "\n",
    "and returns a **combined list**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b471331",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = add_messages([HumanMessage(\"Hi! I'm Oscar. \"), \n",
    "                        AIMessage(\"Hey, Oscar! How can I assist you?\")], \n",
    "                        [HumanMessage(\"Could you summarize today's news?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b7fd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5d3daf",
   "metadata": {},
   "source": [
    "## Defining a Reducer-Aware State\n",
    "\n",
    "By default, LangGraph **replaces** state values after each node.\n",
    "\n",
    "Here, we want **new messages to be appended** instead.\n",
    "\n",
    "Using `Annotated`, we attach the `add_messages` reducer\n",
    "to the `messages` field so that updates are merged\n",
    "instead of overwritten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283878ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d1ec7b",
   "metadata": {},
   "source": [
    "## Chat Model Initialization\n",
    "\n",
    "A deterministic chat model is used to generate responses\n",
    "within graph nodes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaea9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-5-nano\", \n",
    "    temperature=0, \n",
    "    model_kwargs= {\"text\":{\"verbosity\": 'low'}},\n",
    "    ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daf5a28",
   "metadata": {},
   "source": [
    "## Defining Graph Nodes\n",
    "\n",
    "Each node:\n",
    "- Reads the current state\n",
    "- Performs an action\n",
    "- Returns new messages to be merged into state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067d3d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(state: State) -> State:\n",
    "    \n",
    "    print(f\"\\n-------> ENTERING ask_question:\")\n",
    "    for i in state[\"messages\"]:\n",
    "        i.pretty_print()\n",
    "    question = \"What is your question?\"\n",
    "\n",
    "    print(question)\n",
    "    \n",
    "    return State(messages = [AIMessage(question), HumanMessage(input())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3c945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state: State) -> State:\n",
    "    \n",
    "    print(f\"\\n-------> ENTERING chatbot:\")\n",
    "    for i in state[\"messages\"]:\n",
    "        i.pretty_print()\n",
    "    \n",
    "    response = chat.invoke(state[\"messages\"])\n",
    "    response.pretty_print()\n",
    "    \n",
    "    return State(messages = [response])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4251811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_another_question(state: State) -> State:\n",
    "    \n",
    "    print(f\"\\n-------> ENTERING ask_another_question:\")\n",
    "    for i in state[\"messages\"]:\n",
    "        i.pretty_print()\n",
    "    \n",
    "    question = \"Would you like to ask one more question (yes/no)?\"\n",
    "    print(question)\n",
    "    \n",
    "    return State(messages = [AIMessage(question), HumanMessage(input())])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94359b3",
   "metadata": {},
   "source": [
    "## Conditional Routing Function\n",
    "\n",
    "The routing function determines whether the graph:\n",
    "- Continues the conversation\n",
    "- Terminates execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23d7d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def routing_function(state: State) -> Literal[\"ask_question\", \"__end__\"]:\n",
    "    \n",
    "    if state[\"messages\"][-1].content == \"yes\":\n",
    "        return \"ask_question\"\n",
    "    else:\n",
    "        return \"__end__\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55acf2a6",
   "metadata": {},
   "source": [
    "## Building the Conversational Graph\n",
    "\n",
    "Nodes are connected using directed edges.\n",
    "Conditional edges control looping behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27425346",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35290cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_node(\"ask_question\", ask_question)\n",
    "graph.add_node(\"chatbot\", chatbot)\n",
    "graph.add_node(\"ask_another_question\", ask_another_question)\n",
    "\n",
    "graph.add_edge(START, \"ask_question\")\n",
    "graph.add_edge(\"ask_question\", \"chatbot\")\n",
    "graph.add_edge(\"chatbot\", \"ask_another_question\")\n",
    "graph.add_conditional_edges(source = \"ask_another_question\", \n",
    "                            path = routing_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf0cf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_compiled = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d369b9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_compiled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09abb126",
   "metadata": {},
   "source": [
    "## Executing the Graph\n",
    "\n",
    "The graph is invoked with an empty initial state.\n",
    "Messages accumulate across turns due to the reducer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a74a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_compiled.invoke(State(messages = []))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ddb330",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "- Using `add_messages` as a reducer\n",
    "- Attaching reducers via `Annotated`\n",
    "- Preserving conversation history across nodes\n",
    "- Building a looping conversational graph\n",
    "- Conditional routing with accumulated state\n",
    "\n",
    "Reducers enable LangGraph to act as a true\n",
    "multi-turn conversational engine.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langraph_env",
   "language": "python",
   "name": "langraph_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
