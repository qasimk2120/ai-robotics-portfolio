{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88e56932",
   "metadata": {},
   "source": [
    "Classifying text using a custom text classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dfc2a9",
   "metadata": {},
   "source": [
    "# üß† Classifying Text Using a Custom Text Classifier\n",
    "\n",
    "In this notebook, we build a **custom sentiment classifier** using classical machine-learning techniques.\n",
    "\n",
    "The goal is to train a model that can **learn from labeled text data** and then **classify new sentences** as **positive** or **negative**.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Problem Overview\n",
    "\n",
    "- Input: text sentences  \n",
    "- Output: sentiment label (`positive` or `negative`)  \n",
    "- Task type: **Supervised text classification**\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Algorithms Used\n",
    "\n",
    "We compare three common classification algorithms:\n",
    "\n",
    "1. **Logistic Regression**\n",
    "2. **Naive Bayes**\n",
    "3. **Linear Support Vector Machine (SVM)**\n",
    "\n",
    "---\n",
    "\n",
    "## üßÆ Regression vs Classification (Important Distinction)\n",
    "\n",
    "- **Linear Regression** ‚Üí predicts continuous values  \n",
    "- **Logistic Regression** ‚Üí predicts discrete classes (classification)\n",
    "\n",
    "Despite the name, **Logistic Regression is a classification algorithm**.\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7843a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030b06b8",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è Dataset\n",
    "\n",
    "We use a small labeled dataset containing **positive** and **negative** sentences.\n",
    "\n",
    "Each row consists of:\n",
    "- `text` ‚Üí the sentence\n",
    "- `sentiment` ‚Üí the label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4cdd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame([(\"i love spending time with my friends and family\", \"positive\"),\n",
    "(\"that was the best meal i've ever had in my life\", \"positive\"),\n",
    "(\"i feel so grateful for everything i have in my life\", \"positive\"),\n",
    "(\"i received a promotion at work and i couldn't be happier\", \"positive\"),\n",
    "(\"watching a beautiful sunset always fills me with joy\", \"positive\"),\n",
    "(\"my partner surprised me with a thoughtful gift and it made my day\", \"positive\"),\n",
    "(\"i am so proud of my daughter for graduating with honors\", \"positive\"),\n",
    "(\"listening to my favorite music always puts me in a good mood\", \"positive\"),\n",
    "(\"i love the feeling of accomplishment after completing a challenging task\", \"positive\"),\n",
    "(\"i am excited to go on vacation next week\", \"positive\"),\n",
    "(\"i feel so overwhelmed with work and responsibilities\", \"negative\"),\n",
    "(\"the traffic during my commute is always so frustrating\", \"negative\"),\n",
    "(\"i received a parking ticket and it ruined my day\", \"negative\"),\n",
    "(\"i got into an argument with my partner and we're not speaking\", \"negative\"),\n",
    "(\"i have a headache and i feel terrible\", \"negative\"),\n",
    "(\"i received a rejection letter for the job i really wanted\", \"negative\"),\n",
    "(\"my car broke down and it's going to be expensive to fix\", \"negative\"),\n",
    "(\"i'm feeling sad because i miss my friends who live far away\", \"negative\"),\n",
    "(\"i'm frustrated because i can't seem to make progress on my project\", \"negative\"),\n",
    "(\"i'm disappointed because my team lost the game\", \"negative\")],columns=[\"text\", \"sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c952cdc",
   "metadata": {},
   "source": [
    "## üîÄ Shuffling the Dataset\n",
    "\n",
    "We shuffle the data to ensure positive and negative samples are mixed evenly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9c2a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1).reset_index(drop=True)    #we are taking 100% of the data and shuffling it in random order  #drop=true means we don't want old index \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ffb718",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"text\"]      \n",
    "y = data[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf49e32",
   "metadata": {},
   "source": [
    "## üî¢ Converting Text into Numbers (Bag of Words)\n",
    "\n",
    "Machine-learning models require numerical input.\n",
    "\n",
    "We use **CountVectorizer** to:\n",
    "- convert text into tokens\n",
    "- build a vocabulary\n",
    "- represent each sentence as word counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99de5dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using CountVectorizer here so each word becomes a column and each sentence becomes a row and entries are the counts of words in each sentence\n",
    "countVec = CountVectorizer()\n",
    "countVec_fit = countVec.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ccfaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = pd.DataFrame(countVec_fit.toarray(), columns=countVec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c01c808",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e707af",
   "metadata": {},
   "source": [
    "## ‚úÇÔ∏è Train / Test Split\n",
    "\n",
    "- **Training set** ‚Üí used to train the model  \n",
    "- **Test set** ‚Üí used to evaluate performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6182abbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(bag_of_words, y, test_size=0.3, random_state=7)\n",
    "#random state is used to ensure that the split is reproducible and we have the same train and test split each time we run the code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021fea65",
   "metadata": {},
   "source": [
    "## ü§ñ Model 1: Logistic Regression\n",
    "\n",
    "Logistic Regression predicts the **probability of a class** and assigns the most likely label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5184c319",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=1).fit(X_train, y_train)\n",
    "   #fit method is used to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69527e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c97cd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bba68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_lr, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20aaedb",
   "metadata": {},
   "source": [
    "## ü§ñ Model 2: Naive Bayes\n",
    "\n",
    "Naive Bayes:\n",
    "- is probabilistic\n",
    "- assumes word independence\n",
    "- performs very well on text data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c984f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7f5cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating algorithm instance\n",
    "nb = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b387c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nb = nb.predict(X_test)  # making predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0a56dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc15eb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424cb89f",
   "metadata": {},
   "source": [
    "## ü§ñ Model 3: Linear Support Vector Machine (SVM)\n",
    "\n",
    "SVM:\n",
    "- finds the best possible decision boundary\n",
    "- works well in high-dimensional spaces (like text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fc8ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Futher Improving the accuracy using Linear Support Vector Machine\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7962ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SGDClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbfe8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a12834",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_pred_svm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011194d5",
   "metadata": {},
   "source": [
    "## ‚úÖ Final Takeaways\n",
    "\n",
    "- Text must be converted into numerical form before modeling\n",
    "- Bag-of-Words is a strong baseline for text classification\n",
    "- Logistic Regression, Naive Bayes, and Linear SVM are excellent starting models\n",
    "- Comparing multiple models helps identify strengths and weaknesses\n",
    "- This pipeline forms the foundation for more advanced NLP systems"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_course_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
