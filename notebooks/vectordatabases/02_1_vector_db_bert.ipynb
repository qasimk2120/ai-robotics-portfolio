{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "189add98",
   "metadata": {},
   "source": [
    "# Weighted Embeddings for Semantic Search (Pinecone + Sentence Transformers)\n",
    "\n",
    "This notebook demonstrates an advanced semantic search technique:\n",
    "**weighted embeddings**.\n",
    "\n",
    "Instead of embedding a single concatenated text field, each record is split\n",
    "into multiple semantic fields (course + section attributes), embedded separately,\n",
    "and combined using a weighted vector sum.\n",
    "\n",
    "This approach enables:\n",
    "- Emphasizing the most important fields (e.g., section description)\n",
    "- Improving retrieval quality in structured datasets\n",
    "- More controllable semantic search behavior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b912c0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import pandas as pd\n",
    "import pinecone\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pinecone\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a56eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key= os.environ.get(\"PINECONE_API_KEY\"), environment= os.environ.get(\"PINECONE_ENV\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e098ad",
   "metadata": {},
   "source": [
    "## Loading Course Section Dataset\n",
    "\n",
    "The dataset contains both course-level and section-level information.\n",
    "Each record is assigned a unique vector ID using:\n",
    "\n",
    "`course_id_section_id`\n",
    "\n",
    "This ensures a stable unique identifier per section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac4239a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = pd.read_csv(\"../../data/course_section_descriptions.csv\", encoding='ANSI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31368c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "files[\"unique_id\"] = files[\"course_id\"].astype(str) + \"_\" + files[\"section_id\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a2b40f",
   "metadata": {},
   "source": [
    "## Creating Metadata for Retrieval Interpretation\n",
    "\n",
    "Metadata is attached to each vector so results can be interpreted easily.\n",
    "This includes:\n",
    "- course name\n",
    "- section name\n",
    "- section description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf36af2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "files[\"metadata\"] = files.apply(lambda row: {\n",
    "    \"course_name\": row[\"course_name\"],\n",
    "    \"section_name\": row[\"section_name\"],\n",
    "    \"section_description\": row[\"section_description\"]\n",
    "}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a427c4",
   "metadata": {},
   "source": [
    "## Defining Field Weights\n",
    "\n",
    "Each embedding field is assigned a weight based on importance.\n",
    "\n",
    "Higher weight means:\n",
    "- stronger influence on semantic similarity\n",
    "- increased retrieval sensitivity to that field\n",
    "\n",
    "The weights sum to 1.0 for interpretability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05c8964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS = {\n",
    "    \"course_name\": 0.35,\n",
    "    \"course_technology\": 0.15,\n",
    "    \"course_description\": 0.10,\n",
    "    \"section_name\": 0.20,\n",
    "    \"section_description\": 0.25\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b68f2c",
   "metadata": {},
   "source": [
    "## Weighted Embedding Strategy\n",
    "\n",
    "For each record:\n",
    "\n",
    "1. Encode individual fields separately\n",
    "2. Combine embeddings via weighted sum\n",
    "3. Normalize the final embedding vector\n",
    "\n",
    "Normalization ensures the vector length is consistent,\n",
    "which improves cosine similarity behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39cbab6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_embedding(row, model, weights):\n",
    "    e_course_name = model.encode(row['course_name'])\n",
    "    e_course_technology = model.encode(row['course_technology'])\n",
    "    e_course_description = model.encode(row['course_description'])\n",
    "    e_section_name = model.encode(row['section_name'])\n",
    "    e_section_description = model.encode(row['section_description'])\n",
    "\n",
    "    combined = (\n",
    "        weights['course_name'] * e_course_name + weights['course_technology'] * e_course_technology + weights['course_description'] * e_course_description + weights['section_name'] * e_section_name + weights['section_description'] * e_section_description )\n",
    "\n",
    "    combined =  combined / np.linalg.norm(combined)\n",
    "    return combined.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e94332d",
   "metadata": {},
   "source": [
    "## Embedding Model Selection\n",
    "\n",
    "`multi-qa-distilbert-cos-v1` is used because it is optimized for:\n",
    "- semantic search\n",
    "- question-answer retrieval use cases\n",
    "\n",
    "This model outputs embeddings of **768 dimensions**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38b506d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('multi-qa-distilbert-cos-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b899bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "files[\"embeddings\"] = files.apply(lambda row: weighted_embedding(row, model, WEIGHTS), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f565f6bf",
   "metadata": {},
   "source": [
    "## Creating a Pinecone Index for Weighted Embeddings\n",
    "\n",
    "A Pinecone index is created with:\n",
    "- dimension = 768\n",
    "- metric = cosine similarity\n",
    "\n",
    "The index is deleted and recreated if it already exists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c5f1cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"bert\"\n",
    "dimension = 768  # Dimension of the embeddings\n",
    "metric = \"cosine\"  # Similarity metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a13ce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "if index_name in [i.name for i in pc.list_indexes()]:\n",
    "    pc.delete_index(index_name)\n",
    "    print(f\"Deleted existing index '{index_name}'.\")\n",
    "else:\n",
    "    print(f\"{index_name} not in the index list.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa32e75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=dimension,\n",
    "    metric=metric,\n",
    "    spec = ServerlessSpec( cloud=\"aws\", region=\"us-east-1\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ec0a600",
   "metadata": {},
   "outputs": [],
   "source": [
    "index =  pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aa354c",
   "metadata": {},
   "source": [
    "## Upserting Weighted Embeddings into Pinecone\n",
    "\n",
    "Each vector is stored as:\n",
    "- ID: unique_id\n",
    "- Values: weighted embedding vector\n",
    "- Metadata: interpretability fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68880aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_to_upsert = [\n",
    "    (row[\"unique_id\"], row[\"embeddings\"], row[\"metadata\"]) for index, row in files.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1aee1f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.upsert(vectors=vectors_to_upsert)\n",
    "print(\"Data upserted successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503fa281",
   "metadata": {},
   "source": [
    "## Weighted Query Embedding\n",
    "\n",
    "The query is embedded using the same weighted strategy\n",
    "to match the indexed representation.\n",
    "\n",
    "This keeps query and document vectors aligned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28f62838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_query_embedding(query, model, weights):\n",
    "    # encode query as if it belongs to each field\n",
    "    q_course_name = model.encode(query)\n",
    "    q_course_technology = model.encode(query)\n",
    "    q_course_description = model.encode(query)\n",
    "    q_section_name = model.encode(query)\n",
    "    q_section_description = model.encode(query)\n",
    "\n",
    "    combined = (\n",
    "        weights[\"course_name\"] * q_course_name +\n",
    "        weights[\"course_technology\"] * q_course_technology +\n",
    "        weights[\"course_description\"] * q_course_description +\n",
    "        weights[\"section_name\"] * q_section_name +\n",
    "        weights[\"section_description\"] * q_section_description\n",
    "    )\n",
    "\n",
    "    combined = combined / np.linalg.norm(combined)\n",
    "\n",
    "    return combined.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5cc776",
   "metadata": {},
   "source": [
    "## Semantic Search with Weighted Embeddings\n",
    "\n",
    "A semantic query is converted into a weighted embedding\n",
    "and searched against the Pinecone index.\n",
    "\n",
    "Results are filtered using a similarity threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6591cca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"regression in python\"\n",
    "query_embedding = weighted_query_embedding(query, model, WEIGHTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bcd7a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_results = index.query(\n",
    "    vector=query_embedding,\n",
    "    top_k=12,\n",
    "    include_metadata=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f8a004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_threshold = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc2ddb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "for match in query_results['matches']:\n",
    "    if match['score'] >= score_threshold:\n",
    "        course_details =  match.get('metadata', {})\n",
    "        course_name = course_details.get('course_name', 'N/A')\n",
    "        section_name = course_details.get('section_name', 'N/A')\n",
    "        section_description = course_details.get('section_description', 'N/A')\n",
    "        print(f\"Matched Item ID: {match['id']}, Score: {match['score']}\")\n",
    "        print(f\"Course: {course_name} \\nSection: {section_name} \\nDescription: {section_description}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b365c3a2",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated a structured semantic search pipeline using\n",
    "**weighted embeddings**:\n",
    "\n",
    "- Built unique IDs for course sections\n",
    "- Stored interpretability metadata\n",
    "- Embedded structured fields separately\n",
    "- Combined embeddings with a weighted sum\n",
    "- Normalized vectors for cosine similarity\n",
    "- Indexed weighted vectors into Pinecone\n",
    "- Queried Pinecone using the same weighted embedding strategy\n",
    "\n",
    "Weighted embeddings provide a practical approach to improving retrieval\n",
    "quality when working with structured datasets.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinecone-env",
   "language": "python",
   "name": "pinecone-env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
