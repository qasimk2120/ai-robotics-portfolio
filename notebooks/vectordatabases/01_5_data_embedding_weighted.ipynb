{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a7ac6e1",
   "metadata": {},
   "source": [
    "# Weighted Embeddings Semantic Search (Pinecone + Sentence Transformers)\n",
    "\n",
    "This notebook demonstrates **weighted embeddings** for semantic search.\n",
    "\n",
    "Instead of embedding one concatenated text field, each structured field\n",
    "(course + section attributes) is embedded separately and combined using\n",
    "a weighted sum.\n",
    "\n",
    "This approach allows:\n",
    "- prioritizing important fields (e.g., section description)\n",
    "- improving retrieval quality on structured educational datasets\n",
    "- fine-grained search at the section level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93300f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import pandas as pd\n",
    "import pinecone\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pinecone\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6986a9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key= os.environ.get(\"PINECONE_API_KEY\"), environment= os.environ.get(\"PINECONE_ENV\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44b5df5",
   "metadata": {},
   "source": [
    "## Loading Course + Section Dataset\n",
    "\n",
    "Each section is assigned a stable unique identifier:\n",
    "\n",
    "`course_id_section_id`\n",
    "\n",
    "This enables section-level indexing and retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117930bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = pd.read_csv(\"../../data/course_section_descriptions.csv\", encoding='ANSI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09467f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "files[\"unique_id\"] = files[\"course_id\"].astype(str) + \"_\" + files[\"section_id\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87005480",
   "metadata": {},
   "source": [
    "## Metadata Storage\n",
    "\n",
    "Metadata is attached to each vector so results can be interpreted\n",
    "without requiring a lookup table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605a62ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "files[\"metadata\"] = files.apply(lambda row: {\n",
    "    \"course_name\": row[\"course_name\"],\n",
    "    \"section_name\": row[\"section_name\"],\n",
    "    \"section_description\": row[\"section_description\"]\n",
    "}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08eeb2c3",
   "metadata": {},
   "source": [
    "## Field Weights\n",
    "\n",
    "Each field is embedded separately and combined using a weighted sum.\n",
    "\n",
    "Higher weight increases that fieldâ€™s influence on similarity search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b636dd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS = {\n",
    "    \"course_name\": 0.35,\n",
    "    \"course_technology\": 0.15,\n",
    "    \"course_description\": 0.10,\n",
    "    \"section_name\": 0.20,\n",
    "    \"section_description\": 0.25\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7730f008",
   "metadata": {},
   "source": [
    "## Building Weighted Embeddings\n",
    "\n",
    "For each record:\n",
    "1. Encode each field into its own embedding vector\n",
    "2. Combine using weights\n",
    "3. Normalize the final embedding vector\n",
    "\n",
    "Normalization helps cosine similarity behave consistently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6925289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_embedding(row, model, weights):\n",
    "    e_course_name = model.encode(row['course_name'])\n",
    "    e_course_technology = model.encode(row['course_technology'])\n",
    "    e_course_description = model.encode(row['course_description'])\n",
    "    e_section_name = model.encode(row['section_name'])\n",
    "    e_section_description = model.encode(row['section_description'])\n",
    "\n",
    "    combined = (\n",
    "        weights['course_name'] * e_course_name + weights['course_technology'] * e_course_technology + weights['course_description'] * e_course_description + weights['section_name'] * e_section_name + weights['section_description'] * e_section_description )\n",
    "\n",
    "    combined =  combined / np.linalg.norm(combined)\n",
    "    return combined.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aacd872",
   "metadata": {},
   "source": [
    "## Embedding Model\n",
    "\n",
    "`all-MiniLM-L6-v2` is used to generate embeddings:\n",
    "- general purpose semantic embeddings\n",
    "- 384 dimensional vectors\n",
    "- small and fast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e50c6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b6b9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "files[\"embeddings\"] = files.apply(lambda row: weighted_embedding(row, model, WEIGHTS), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd8718e",
   "metadata": {},
   "source": [
    "## Creating Pinecone Index\n",
    "\n",
    "The Pinecone index must match the embedding dimension.\n",
    "\n",
    "Here:\n",
    "- dimension = 384 (MiniLM)\n",
    "- metric = cosine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a192ecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"my-index\"\n",
    "dimension = 384  # Dimension of the embeddings\n",
    "metric = \"cosine\"  # Similarity metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe2ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "if index_name in [i.name for i in pc.list_indexes()]:\n",
    "    pc.delete_index(index_name)\n",
    "    print(f\"Deleted existing index '{index_name}'.\")\n",
    "else:\n",
    "    print(f\"{index_name} not in the index list.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d3ced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=dimension,\n",
    "    metric=metric,\n",
    "    spec = ServerlessSpec( cloud=\"aws\", region=\"us-east-1\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90971c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index =  pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959a4718",
   "metadata": {},
   "source": [
    "## Upserting Weighted Vectors\n",
    "\n",
    "Vectors are inserted into Pinecone as:\n",
    "- ID: unique section identifier\n",
    "- Values: weighted embedding\n",
    "- Metadata: course + section info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6daf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_to_upsert = [\n",
    "    (row[\"unique_id\"], row[\"embeddings\"], row[\"metadata\"]) for index, row in files.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccd3f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.upsert(vectors=vectors_to_upsert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36017fa7",
   "metadata": {},
   "source": [
    "## Weighted Query Embedding\n",
    "\n",
    "The query is embedded using the same weighted strategy\n",
    "to align query vector space with the indexed vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5464549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_query_embedding(query, model, weights):\n",
    "    # encode query as if it belongs to each field\n",
    "    q_course_name = model.encode(query)\n",
    "    q_course_technology = model.encode(query)\n",
    "    q_course_description = model.encode(query)\n",
    "    q_section_name = model.encode(query)\n",
    "    q_section_description = model.encode(query)\n",
    "\n",
    "    combined = (\n",
    "        weights[\"course_name\"] * q_course_name +\n",
    "        weights[\"course_technology\"] * q_course_technology +\n",
    "        weights[\"course_description\"] * q_course_description +\n",
    "        weights[\"section_name\"] * q_section_name +\n",
    "        weights[\"section_description\"] * q_section_description\n",
    "    )\n",
    "\n",
    "    combined = combined / np.linalg.norm(combined)\n",
    "\n",
    "    return combined.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58254e83",
   "metadata": {},
   "source": [
    "## Semantic Search\n",
    "\n",
    "A query is embedded and searched against the Pinecone index.\n",
    "Results above a similarity threshold are displayed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65252022",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"regression in python\"\n",
    "query_embedding = weighted_query_embedding(query, model, WEIGHTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bb7170",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_results = index.query(\n",
    "    vector=query_embedding,\n",
    "    top_k=12,\n",
    "    include_metadata=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dec339",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_threshold = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14bba1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for match in query_results['matches']:\n",
    "    if match['score'] >= score_threshold:\n",
    "        course_details =  match.get('metadata', {})\n",
    "        course_name = course_details.get('course_name', 'N/A')\n",
    "        section_name = course_details.get('section_name', 'N/A')\n",
    "        section_description = course_details.get('section_description', 'N/A')\n",
    "        print(f\"Matched Item ID: {match['id']}, Score: {match['score']}\")\n",
    "        print(f\"Course: {course_name} \\nSection: {section_name} \\nDescription: {section_description}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751a6fc7",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated **weighted embeddings semantic search**:\n",
    "\n",
    "- Created section-level IDs (course_id_section_id)\n",
    "- Stored interpretability metadata\n",
    "- Embedded multiple structured fields separately\n",
    "- Combined embeddings using weighted sum\n",
    "- Normalized final vectors for cosine similarity\n",
    "- Indexed the result in Pinecone\n",
    "- Queried Pinecone using aligned weighted query embeddings\n",
    "\n",
    "Weighted embedding strategies are useful when structured fields\n",
    "do not contribute equally to semantic relevance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinecone-env",
   "language": "python",
   "name": "pinecone-env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
