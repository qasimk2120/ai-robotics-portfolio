{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dc86cb9",
   "metadata": {},
   "source": [
    "# ðŸ¤– BERT Question Answering with Transformers\n",
    "\n",
    "This notebook demonstrates how a pre-trained BERT model performs\n",
    "**extractive question answering** by predicting the start and end\n",
    "positions of an answer within a given context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a12db55",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ What is BERT?\n",
    "\n",
    "BERT (Bidirectional Encoder Representations from Transformers) is a\n",
    "Transformer-based model trained on large text corpora.\n",
    "\n",
    "Key points:\n",
    "- Trained on the **BooksCorpus** dataset (~11,000 books)\n",
    "- Trained on a large **Wikipedia** text corpus\n",
    "- Uses **bidirectional context**, reading text left-to-right and right-to-left\n",
    "- BERT Base has ~110M parameters\n",
    "- BERT Large has ~340M parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea8574e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForQuestionAnswering, BertTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cba5f04",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Loading a Pre-trained BERT Model\n",
    "\n",
    "Here we load a BERT model fine-tuned for **question answering** on the\n",
    "SQuAD dataset, along with its corresponding tokenizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5319ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-large-uncased-whole-word-masking-finetuned-squad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6efcdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  BertForQuestionAnswering.from_pretrained(model_name)   #loading the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b915e716",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(model_name)   #loading the pre-trained tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07b4618",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Preparing Question and Context\n",
    "\n",
    "To perform question answering, BERT requires:\n",
    "- A question\n",
    "- A context passage containing the answer\n",
    "\n",
    "Both are encoded together as a single input sequence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0146128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example question and text containing the answer\n",
    "question = \"When was the first dvd released?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8d4dbaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_document = \"The first DVD (Digital Versatile Disc) was released on March 24, 1997. It was a movie titled 'Twister' and was released in Japan. DVDs quickly gained popularity as a replacement for VHS tapes and became a common format for storing and distributing digital video and data.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a045a81b",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Tokenizing Questionâ€“Context Pairs\n",
    "\n",
    "The tokenizer encodes the question and context together, producing:\n",
    "- Input IDs\n",
    "- Token type (segment) IDs\n",
    "- Special tokens such as `[CLS]` and `[SEP]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431e1128",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = bert_tokenizer.encode_plus(text= question, text_pair=answer_document)  #tokenizing the question and answer text pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9ec7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d6f8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = encoding['input_ids']  #getting the input ids from the encoding\n",
    "sentence_embeddings = encoding['token_type_ids']   #getting the segment ids from the encoding\n",
    "tokens =  tokenizer.convert_ids_to_tokens(inputs)   #converting the input ids to tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5bdd07",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ Running the BERT Model\n",
    "\n",
    "The encoded inputs are passed into the BERT question answering model.\n",
    "The model outputs:\n",
    "- Start logits (where the answer begins)\n",
    "- End logits (where the answer ends)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac56cc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e656979e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(102)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c558794c",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ Running the BERT Model\n",
    "\n",
    "The encoded inputs are passed into the BERT question answering model.\n",
    "The model outputs:\n",
    "- Start logits (where the answer begins)\n",
    "- End logits (where the answer ends)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0664844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output =  model(input_ids = torch.tensor([inputs]), token_type_ids= torch.tensor([sentence_embeddings]) )  #getting the model output "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b004bf",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ Extracting the Answer Span\n",
    "\n",
    "The answer is extracted by selecting the tokens with the highest\n",
    "start and end scores and joining them into a readable string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de77fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = torch.argmax(output.start_logits)\n",
    "end_index = torch.argmax(output.end_logits)\n",
    "\n",
    "print(start_index)\n",
    "print(end_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de8dbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = ' '.join(tokens[start_index: end_index+1])  #getting the answer from the tokens\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f60286",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ Visualizing Start and End Scores\n",
    "\n",
    "To understand model confidence, we visualize:\n",
    "- Start logits per token\n",
    "- End logits per token\n",
    "\n",
    "Higher values indicate stronger confidence that a token\n",
    "marks the beginning or end of the answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b28ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt \n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa3620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_scores = output.start_logits.detach().numpy().flatten()\n",
    "e_scores = output.end_logits.detach().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eb3522",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_labels = []   #we want token labels as a list of strings with token and its index\n",
    "for (i, token) in enumerate(tokens):\n",
    "    tokens_labels.append('{:} - {:>2}'.format(token, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d37b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax =  sns.barplot(x=tokens_labels, y=s_scores) \n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"center\")\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6137af21",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax =  sns.barplot(x=tokens_labels, y=e_scores)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"center\")\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6afcfa5",
   "metadata": {},
   "source": [
    "## âœ… Key Takeaways\n",
    "\n",
    "- BERT performs extractive question answering using token span prediction\n",
    "- Question and context are processed together\n",
    "- Start and end logits determine the answer\n",
    "- Visualization helps interpret model behavior\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (huggingfaceenv)",
   "language": "python",
   "name": "huggingfaceenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
