{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fddb5ed2",
   "metadata": {},
   "source": [
    "# LangChain Expression Language (LCEL)\n",
    "\n",
    "This notebook demonstrates the **LangChain Expression Language (LCEL)**,\n",
    "which enables composing prompt templates, models, and output parsers\n",
    "into a single executable pipeline.\n",
    "\n",
    "The focus is on:\n",
    "- Building prompt templates with structured instructions\n",
    "- Parsing model output into deterministic formats\n",
    "- Composing components using the pipe (`|`) operator\n",
    "- Executing end-to-end chains in a single expression\n",
    "\n",
    "LCEL provides a concise and readable way to define LLM workflows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12bdb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f3b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191b55d6",
   "metadata": {},
   "source": [
    "## Output Format Instructions\n",
    "\n",
    "Before building the prompt, we define formatting instructions\n",
    "using an output parser.\n",
    "\n",
    "These instructions are injected into the prompt to ensure\n",
    "the model returns a predictable, structured response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1646c77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_intructions =  CommaSeparatedListOutputParser().get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febc939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_intructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616083de",
   "metadata": {},
   "source": [
    "## Model Initialization\n",
    "\n",
    "A deterministic chat model is initialized to ensure\n",
    "consistent and parseable outputs when chaining components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863a31f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-5-nano\", \n",
    "    temperature=0, \n",
    "    model_kwargs= {\"text\":{\"verbosity\": 'low'},\"reasoning\":{\"effort\": \"medium\"}},\n",
    "    \n",
    "    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77267f9",
   "metadata": {},
   "source": [
    "## Prompt Template Construction\n",
    "\n",
    "A `ChatPromptTemplate` is created with a dynamic placeholder\n",
    "and embedded formatting instructions.\n",
    "\n",
    "This template defines the structure of the user request\n",
    "without executing the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035e921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages([('human', \"I've recently adopted a {pet}, Can you suggest three {pet} names? \\n\" + list_intructions)])\n",
    "chat_template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59ba4a7",
   "metadata": {},
   "source": [
    "## Manual Invocation and Parsing\n",
    "\n",
    "Before using LCEL, the prompt, model, and output parser\n",
    "can be invoked step by step to observe intermediate results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86ab228",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_output_parser =  CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ce6023",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template_result = chat_template.invoke({\"pet\": \"dog\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea5a30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_result = chat.invoke(chat_template_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7430aa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_output_parser.invoke(chat_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb25da9",
   "metadata": {},
   "source": [
    "## LangChain Expression Language (LCEL)\n",
    "\n",
    "Using LCEL, individual components can be composed into a single\n",
    "executable chain using the pipe (`|`) operator.\n",
    "\n",
    "This allows the entire workflow to be expressed concisely\n",
    "in one readable line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "593ccf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_template | chat | list_output_parser   # Create a chain by piping components together using expression language, all of the above process in one line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c1e72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"pet\": \"cat\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7fae58",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "- Defining structured output instructions  \n",
    "- Creating reusable chat prompt templates  \n",
    "- Parsing model output into deterministic lists  \n",
    "- Composing prompt, model, and parser using LCEL  \n",
    "- Executing end-to-end chains in a single expression  \n",
    "\n",
    "LCEL simplifies complex LLM workflows while\n",
    "maintaining clarity and composability.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchains_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
